{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c259ab7c3cfb3b038626a45f263de859f192b1c8"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl_params = {\n",
    "    'figure.figsize': (10, 5),\n",
    "    'figure.dpi': 300,\n",
    "}\n",
    "from matplotlib import pyplot as plt\n",
    "mpl.rcParams.update(mpl_params)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6797f82b550dc9b4539497dcceb0108f71e04454"
   },
   "source": [
    "**Inception V2/V3 paper**\n",
    "\n",
    "https://arxiv.org/pdf/1512.00567v3.pdf\n",
    "\n",
    "**PyTorch InceptionV3 source**\n",
    "\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py\n",
    "\n",
    "**InceptionV3 Tranfer Learning Gist (Some of the notebook from here)** \n",
    "\n",
    "https://gist.github.com/Prakashvanapalli/fba135778219c37bacc744d8dbfb43b1\n",
    "\n",
    "**PyTorch: Deep Learning (PyData Berlin 2018) (Most of notebook based off this talk/notebooks)** \n",
    "\n",
    "https://github.com/sotte/pytorch_tutorial/blob/master/notebooks/00_index.ipynb\n",
    "\n",
    "**InceptionV1 and InceptionV3 available from PyTorch**\n",
    "\n",
    "**InceptionV2 and InceptionV4 available from**\n",
    "\n",
    "https://github.com/Cadene/pretrained-models.pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "776d4b7256c17b44f7e22c4e5d23b0c15b3c9441"
   },
   "source": [
    "# TODO:\n",
    "\n",
    "Learn about this:\n",
    "\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    \n",
    "Pillow SIMD Install in Conda env:\n",
    "\n",
    "    https://gist.github.com/soumith/01da3874bf014d8a8c53406c2b95d56b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93299dccf566314240238bfc0556e1e14dd66e15"
   },
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1a638cedbd14ff214fcdc95e99ae026a5b73128c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e704781aa51a7e7159374d7f3f20ea05307fad6b"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Required to implement `__len__` and `__getitem__`. \n",
    "\n",
    "+ labels convenience attributes\n",
    "+ image display helpers\n",
    "+ ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "65248726c0b9f1d8655110d73211cf1fb337e9e5"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('../input/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e331013f414d58d12f9aed0f8b338e6ea41fc534"
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0: 'Nucleoplasm', \n",
    "    1: 'Nuclear membrane',   \n",
    "    2: 'Nucleoli',   \n",
    "    3: 'Nucleoli fibrillar center' ,  \n",
    "    4: 'Nuclear speckles',\n",
    "    5: 'Nuclear bodies',\n",
    "    6: 'Endoplasmic reticulum',   \n",
    "    7: 'Golgi apparatus',\n",
    "    8: 'Peroxisomes',\n",
    "    9: 'Endosomes',\n",
    "    10: 'Lysosomes',\n",
    "    11: 'Intermediate filaments',   \n",
    "    12: 'Actin filaments',\n",
    "    13: 'Focal adhesion sites',   \n",
    "    14: 'Microtubules',\n",
    "    15: 'Microtubule ends',   \n",
    "    16: 'Cytokinetic bridge',   \n",
    "    17: 'Mitotic spindle',\n",
    "    18: 'Microtubule organizing center',  \n",
    "    19: 'Centrosome',\n",
    "    20: 'Lipid droplets',   \n",
    "    21: 'Plasma membrane',   \n",
    "    22: 'Cell junctions', \n",
    "    23: 'Mitochondria',\n",
    "    24: 'Aggresome',\n",
    "    25: 'Cytosol',\n",
    "    26: 'Cytoplasmic bodies',   \n",
    "    27: 'Rods & rings'\n",
    "}\n",
    "\n",
    "LABEL_NAMES = list(LABELS.values())\n",
    "LABEL_KEYS = list(LABELS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "40c0b6e56d79e8166834ae2880b37799a5341c6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1b46ec081087a75038e721e73badcaeeac21d148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 1, 2, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x) for x in df.iloc[1].Target.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7c7360c47d2bf956a0278ec87f1ee36ca034e69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0_blue.png\n",
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0_green.png\n",
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0_red.png\n",
      "00070df0-bbc3-11e8-b2bc-ac1f6b6435d0_yellow.png\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_blue.png\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_green.png\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_red.png\n",
      "000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_yellow.png\n",
      "000a9596-bbc4-11e8-b2bc-ac1f6b6435d0_blue.png\n",
      "000a9596-bbc4-11e8-b2bc-ac1f6b6435d0_green.png\n"
     ]
    }
   ],
   "source": [
    "ls '../input/train/' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "6c8d69d944c8c8a51a5f246e0f5413af149960f3"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_df, images_dir, transform=None):            \n",
    "        self.df = train_df.copy()  # TODO: Rename. Actualy replace df maybe?\n",
    "        self._dir = images_dir # TODO: PIL check?\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "                                      \n",
    "    def __getitem__(self, key):\n",
    "        id_ = self.df.iloc[key].Id\n",
    "        \n",
    "        #  TODO: Clean this up...\n",
    "        r = np.array(Image.open(self._dir / f'{id_}_red.png'), np.uint8)\n",
    "        g = np.array(Image.open(self._dir / f'{id_}_green.png'), np.uint8)\n",
    "        b = np.array(Image.open(self._dir / f'{id_}_blue.png'), np.uint8)\n",
    "        y = np.array(Image.open(self._dir / f'{id_}_yellow.png'), np.uint8)\n",
    "        \n",
    "        rgb = np.stack([\n",
    "            r // 2 + y // 2,\n",
    "            g // 2 + y // 2,\n",
    "            b // 2\n",
    "        ], axis=2)\n",
    "        \n",
    "        rgb = np.array(Image.fromarray(rgb).resize((299, 299)))  # InceptionV3 input\n",
    "        rgb = np.array(rgb) / 255.0  # 0.0 - 1.0 floats Better way?\n",
    "        \n",
    "        y = [int(x) for x in self.df.iloc[key].Target.split()]\n",
    "        \n",
    "        if transform:\n",
    "            X = self.transform(rgb)\n",
    "        else:\n",
    "            X = rgb\n",
    "            \n",
    "        return X, y  # TODO: Generator..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "117ff6d428c2301d5cd3d76761db8dd8ee9a74cd"
   },
   "source": [
    "# Transforms\n",
    "\n",
    "*Get pillow-simd*  https://github.com/uploadcare/pillow-simd /  http://python-pillow.org/pillow-perf/\n",
    "\n",
    "1. How to combine images\n",
    "2. PIL -> Tensor\n",
    "3. Normalize?\n",
    "\n",
    "+ Augment labels with least samples?\n",
    "+ ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "9207698551ecaad9231efc9149c51b50f4336e6a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "8b1695b7ecfef947753a6638b1f3dca220343b7b"
   },
   "outputs": [],
   "source": [
    "val_ds = ProteinDataset(df, Path('../input/train'), transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5d99f55043f3f5ee8d8cfb8ae5bc35e81d544c18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0157, 0.0000, 0.0000,  ..., 0.0039, 0.0078, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0235,  ..., 0.0039, 0.0078, 0.0275],\n",
       "          [0.0078, 0.0157, 0.0000,  ..., 0.0118, 0.0549, 0.0275],\n",
       "          ...,\n",
       "          [0.0078, 0.0039, 0.0118,  ..., 0.0314, 0.0000, 0.0588],\n",
       "          [0.0196, 0.0431, 0.0275,  ..., 0.0431, 0.0667, 0.0000],\n",
       "          [0.0000, 0.0078, 0.0000,  ..., 0.0157, 0.0039, 0.0039]],\n",
       " \n",
       "         [[0.0157, 0.0510, 0.0000,  ..., 0.0000, 0.0078, 0.0000],\n",
       "          [0.1020, 0.0706, 0.0510,  ..., 0.0039, 0.0353, 0.0000],\n",
       "          [0.0275, 0.0431, 0.0706,  ..., 0.0314, 0.0431, 0.0196],\n",
       "          ...,\n",
       "          [0.0078, 0.0000, 0.0314,  ..., 0.0431, 0.0000, 0.0039],\n",
       "          [0.0235, 0.0275, 0.0235,  ..., 0.0039, 0.0157, 0.0039],\n",
       "          [0.0000, 0.0039, 0.0000,  ..., 0.0118, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0392, 0.0078,  ..., 0.0235, 0.0157, 0.0000],\n",
       "          [0.0235, 0.0275, 0.0196,  ..., 0.0078, 0.0000, 0.0000],\n",
       "          [0.0275, 0.0000, 0.0157,  ..., 0.0118, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0039, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64), [16, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3af8cc60ff3ac28da3b00860fab36bcdec789930"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "e85d78c8bbea1c6c443135dd65a83ad8fc53779a"
   },
   "outputs": [],
   "source": [
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6de40a91ddea0217358d398e3254145307efa242"
   },
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "668ad24448707f1da581c7d73b76fa7c19568c53"
   },
   "source": [
    "# PreTrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "57e17d6d06824561ec9287cbeb218241269a58c8"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.inception_v3(pretrained=True).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2adf79de4d97778cc45584df77a4def6da16d855"
   },
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0c352e8d8e7039ddfbc50bfd7921b0c77eaf0a21"
   },
   "outputs": [],
   "source": [
    "# Freeze all layers, change fully connected layer from 1000 outputs to our 28 label output, unfreeze last layer\n",
    "# How to change this from single classification to multilabel classification?\n",
    "# \n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "# n_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(n_features, len(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f3cf8091c8333d30f3cb282cfb93b2083371ff4"
   },
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1fd03476af1966fe8100cd7ba3fb63a9cce6c5e"
   },
   "source": [
    "### Forward Hook for Feature Extraction\n",
    "\n",
    "https://discuss.pytorch.org/t/how-to-get-separate-conv-feature-map-from-pretrained-resnet/3479/4?u=justusschock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "66f06fdb509df4f940d62c5eb99dacc1d36ee67f"
   },
   "outputs": [],
   "source": [
    "# features1a = []\n",
    "# def hook1a(module, input, output):\n",
    "#     features1a.extend(output)\n",
    "\n",
    "# model.Conv2d_1a_3x3.register_forward_hook(hook1a)\n",
    "\n",
    "# features2b = []\n",
    "# def hook2b(module, input, output):\n",
    "#     features2b.extend(output)\n",
    "\n",
    "# model.Conv2d_2b_3x3.register_forward_hook(hook2b)\n",
    "\n",
    "# features3b = []\n",
    "# def hook3b(module, input, output):\n",
    "#     features3b.extend(output)\n",
    "\n",
    "# model.Conv2d_3b_1x1.register_forward_hook(hook3b)\n",
    "\n",
    "# features4a = []\n",
    "# def hook4a(module, input, output):\n",
    "#     features4a.extend(output)\n",
    "\n",
    "# model.Conv2d_4a_3x3.register_forward_hook(hook4a)\n",
    "\n",
    "#     def __init__(self, num_classes=1000, aux_logits=True, transform_input=False):\n",
    "#         super(Inception3, self).__init__()\n",
    "#         self.aux_logits = aux_logits\n",
    "#         self.transform_input = transform_input\n",
    "#         self.Conv2d_1a_3x3 = BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "#         self.Conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=3)\n",
    "#         self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.Conv2d_3b_1x1 = BasicConv2d(64, 80, kernel_size=1)\n",
    "#         self.Conv2d_4a_3x3 = BasicConv2d(80, 192, kernel_size=3)\n",
    "#         self.Mixed_5b = InceptionA(192, pool_features=32)\n",
    "#         self.Mixed_5c = InceptionA(256, pool_features=64)\n",
    "#         self.Mixed_5d = InceptionA(288, pool_features=64)\n",
    "#         self.Mixed_6a = InceptionB(288)\n",
    "#         self.Mixed_6b = InceptionC(768, channels_7x7=128)\n",
    "#         self.Mixed_6c = InceptionC(768, channels_7x7=160)\n",
    "#         self.Mixed_6d = InceptionC(768, channels_7x7=160)\n",
    "#         self.Mixed_6e = InceptionC(768, channels_7x7=192)\n",
    "#         if aux_logits:\n",
    "#             self.AuxLogits = InceptionAux(768, num_classes)\n",
    "#         self.Mixed_7a = InceptionD(768)\n",
    "#         self.Mixed_7b = InceptionE(1280)\n",
    "#         self.Mixed_7c = InceptionE(2048)\n",
    "#         self.fc = nn.Linear(2048, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e64a7d2f36334ce0cd4712f0f8af7faba98f62c"
   },
   "source": [
    "## Visualize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1b59f97070138f1052c4c8e1660c2ea3cf841610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x12b64e0b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def grid(layer_weights):\n",
    "    n, rows, cols = layer_weights.shape\n",
    "    grid_size = int(np.ceil(np.sqrt(n)))\n",
    "    grid_total = grid_size * grid_size\n",
    "    n_empty = grid_total - n\n",
    "    layer_weights = np.concatenate([layer_weights, np.zeros((n_empty, rows, cols))])\n",
    "    layer_weights = layer_weights.reshape((grid_size, grid_size, rows, cols))\n",
    "    im_array = np.vstack([np.hstack([col for col in row]) for row in layer_weights])\n",
    "    im_array *= 255.0\n",
    "    pil_im = Image.fromarray(im_array)\n",
    "    return pil_im\n",
    "\n",
    "layers = itertools.cycle([\n",
    "    'Conv2d_1a_3x3',\n",
    "    'Conv2d_2a_3x3',\n",
    "    'Conv2d_2b_3x3',\n",
    "    'Conv2d_3b_1x1',\n",
    "    'Conv2d_4a_3x3',\n",
    "    'Mixed_5b',\n",
    "    'Mixed_5c',\n",
    "    'Mixed_5d',\n",
    "    'Mixed_6a',\n",
    "    'Mixed_6b',\n",
    "    'Mixed_6c',\n",
    "    'Mixed_6d',\n",
    "    'Mixed_6e',\n",
    "    'Mixed_7a',\n",
    "    'Mixed_7b',\n",
    "    'Mixed_7c'\n",
    "])\n",
    "\n",
    "label_dir = ''\n",
    "\n",
    "\n",
    "def hook(module, input, output):\n",
    "    grid(output.squeeze()).convert('L').save(f'{label_dir}/{next(layers)}.png')\n",
    "\n",
    "model.Conv2d_1a_3x3.register_forward_hook(hook)\n",
    "# 149 x 149 x 32\n",
    "\n",
    "model.Conv2d_2a_3x3.register_forward_hook(hook)\n",
    "# 147 x 147 x 32\n",
    "\n",
    "model.Conv2d_2b_3x3.register_forward_hook(hook)\n",
    "# 147 x 147 x 64\n",
    "\n",
    "model.Conv2d_3b_1x1.register_forward_hook(hook)\n",
    "# 73 x 73 x 80\n",
    "\n",
    "model.Conv2d_4a_3x3.register_forward_hook(hook)\n",
    "# 71 x 71 x 192\n",
    "\n",
    "model.Mixed_5b.register_forward_hook(hook)\n",
    "# 35 x 35 x 256\n",
    "\n",
    "model.Mixed_5c.register_forward_hook(hook)\n",
    "# 35 x 35 x 288\n",
    "\n",
    "model.Mixed_5d.register_forward_hook(hook)\n",
    "# 35 x 35 x 288\n",
    "\n",
    "model.Mixed_6a.register_forward_hook(hook)\n",
    "# 17 x 17 x 768\n",
    "\n",
    "model.Mixed_6b.register_forward_hook(hook)\n",
    "# 17 x 17 x 768\n",
    "\n",
    "model.Mixed_6c.register_forward_hook(hook)\n",
    "# 17 x 17 x 768\n",
    "\n",
    "model.Mixed_6d.register_forward_hook(hook)\n",
    "# 17 x 17 x 768\n",
    "\n",
    "model.Mixed_6e.register_forward_hook(hook)\n",
    "# 17 x 17 x 768\n",
    "\n",
    "model.Mixed_7a.register_forward_hook(hook)\n",
    "# 8 x 8 x 1280\n",
    "\n",
    "model.Mixed_7b.register_forward_hook(hook)\n",
    "# 8 x 8 x 2048\n",
    "\n",
    "model.Mixed_7c.register_forward_hook(hook)\n",
    "# 8 x 8 x 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "e95e2879afa4078d1d8f97151b0ce3fd91960a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5_Nuclear bodies\n",
      "Created 1_Nuclear membrane\n",
      "Created 18_Microtubule organizing center\n",
      "Created 0_Nucleoplasm\n",
      "Created 7_Golgi apparatus\n",
      "Created 23_Mitochondria\n",
      "Created 21_Plasma membrane\n",
      "Created 25_Cytosol\n",
      "Created 11_Intermediate filaments\n",
      "Created 13_Focal adhesion sites\n",
      "Created 12_Actin filaments\n",
      "Created 2_Nucleoli\n",
      "Created 20_Lipid droplets\n",
      "Created 3_Nucleoli fibrillar center\n",
      "Created 14_Microtubules\n",
      "Created 17_Mitotic spindle\n",
      "Created 19_Centrosome\n",
      "Created 6_Endoplasmic reticulum\n",
      "Created 4_Nuclear speckles\n",
      "Created 10_Lysosomes\n",
      "Created 26_Cytoplasmic bodies\n",
      "Created 22_Cell junctions\n",
      "Created 8_Peroxisomes\n",
      "Created 24_Aggresome\n",
      "Created 16_Cytokinetic bridge\n",
      "Created 9_Endosomes\n",
      "Created 15_Microtubule ends\n",
      "Created 27_Rods & rings\n",
      "701.5315017700195\n"
     ]
    }
   ],
   "source": [
    "start_ts = time.time()\n",
    "model.eval()\n",
    "labels_collected = []\n",
    "with torch.no_grad():\n",
    "    for X, y in val_dl:\n",
    "        if len(y) > 1 and 10 not in y and 15 not in y and 17 not in y:\n",
    "            continue\n",
    "            \n",
    "        if 10 in y:\n",
    "            single_label = 10\n",
    "        elif 15 in y:\n",
    "            single_label = 15\n",
    "        elif 17 in y:\n",
    "            single_label = 17\n",
    "        else:\n",
    "            single_label = int(y[0])\n",
    "\n",
    "        if single_label in labels_collected:\n",
    "            continue\n",
    "            \n",
    "        labels_collected.append(single_label)\n",
    "\n",
    "        label_dir = f'{str(single_label)}_{LABELS[single_label]}'\n",
    "        Path(label_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        t1 = time.time()\n",
    "        model(X)\n",
    "        print(f'Created {label_dir}') # Processed: {len(features2b)} Total: {len(val_ds)} {time.time() - t1}')\n",
    "print(time.time() - start_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47744934fb2cc55e5babc9383b275c247e2cc5b7"
   },
   "source": [
    "# Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62843778835543e5b529508f6102a70c808b2384"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9b028504b84d4845e29e943e669833c6863e5bd"
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f204eb88aa3bc714eb18be41f5ff54425b733b8"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "0078421556d704943c2319ef793c760c1b57bc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 0.661773681640625\n",
      "Loaded in 0.7015519142150879\n",
      "Loaded in 0.7658672332763672\n",
      "Loaded in 0.8106927871704102\n",
      "Loaded in 0.9024658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-97:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-42-720500edf817>\", line 23, in __getitem__\n",
      "    b // 2\n",
      "KeyboardInterrupt\n",
      "Process Process-98:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-30cfbad07b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count = 0\\nwith torch.no_grad():\\n    t1 = time.time()\\n    for X, y in val_dl:\\n        print(f'Loaded in {time.time() - t1}')\\n        count += 1\\n        if count > 0:\\n            break\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 187, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 187, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/Users/david.wagner/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 164, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    t1 = time.time()\n",
    "    for X, y in val_dl:\n",
    "        print(f'Loaded in {time.time() - t1}')\n",
    "        count += 1\n",
    "        if count > 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_load(fn):\n",
    "    pil_im = Image.open(fn)\n",
    "    return np.array(pil_im, np.uint8)\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "p = Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33272600173950195\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for _ in range(32):\n",
    "    id_ = '00070df0-bbc3-11e8-b2bc-ac1f6b6435d0'\n",
    "    key = 0\n",
    "    images_dir = Path('../input/train')\n",
    "\n",
    "    #  TODO: Clean this up...\n",
    "#     r = np.array(Image.open(images_dir / f'{id_}_red.png'), np.uint8)\n",
    "#     g = np.array(Image.open(images_dir / f'{id_}_green.png'), np.uint8)\n",
    "#     b = np.array(Image.open(images_dir / f'{id_}_blue.png'), np.uint8)\n",
    "#     y = np.array(Image.open(images_dir / f'{id_}_yellow.png'), np.uint8)\n",
    "\n",
    "    r, g, b, y = p.map(mp_load, [(images_dir / f'{id_}_red.png'),\n",
    "                                 (images_dir / f'{id_}_green.png'), \n",
    "                                 (images_dir / f'{id_}_blue.png'), \n",
    "                                 (images_dir / f'{id_}_yellow.png'),])\n",
    "\n",
    "    rgb = np.stack([\n",
    "        r // 2 + y // 2,\n",
    "        g // 2 + y // 2,\n",
    "        b // 2\n",
    "    ], axis=2)\n",
    "\n",
    "    rgb = np.array(Image.fromarray(rgb).resize((299, 299)))  # InceptionV3 input\n",
    "    rgb = np.array(rgb) / 255.0  # 0.0 - 1.0 floats Better way?\n",
    "\n",
    "#     y = [int(x) for x in df.iloc[key].Target.split()]\n",
    "\n",
    "    X = transform(rgb)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007842063903808594"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "id_ = '00070df0-bbc3-11e8-b2bc-ac1f6b6435d0'\n",
    "key = 0\n",
    "images_dir = Path('../input/train')\n",
    "p.map(mp_load, [(images_dir / f'{id_}_red.png'),\n",
    "                (images_dir / f'{id_}_green.png'), \n",
    "                (images_dir / f'{id_}_blue.png'), \n",
    "                (images_dir / f'{id_}_yellow.png'),])\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060882568359375"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Image.open(images_dir / f'{df.loc[12].Id}_red.png')\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004925966262817383"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "rgb = np.stack([\n",
    "    r // 2 + y // 2,\n",
    "    g // 2 + y // 2,\n",
    "    b // 2\n",
    "], axis=2)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017452239990234375"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "test = np.array(Image.fromarray(rgb).resize((299, 299)))  # InceptionV3 input\n",
    "test2 = np.array(test) / 255.0  # 0.0 - 1.0 floats Better way?\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512.00567v3.pdf           draft_vis.ipynb            \u001b[34minception_visualization\u001b[m\u001b[m/   kernel.ipynb               test.npy\n",
      "InceptionLayers.zip        explore.ipynb              inceptionv3.ipynb          row.png                    visualize_inception.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 1 2 0'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Target.tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_list = iter(df.Target.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 1 2 0'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(next_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 37 µs, total: 43 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "torch.save(x, 'test_tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Write a pickled representation of obj to the open file object file.\n",
       "\n",
       "This is equivalent to ``Pickler(file, protocol).dump(obj)``, but may\n",
       "be more efficient.\n",
       "\n",
       "The optional *protocol* argument tells the pickler to use the given\n",
       "protocol supported protocols are 0, 1, 2, 3 and 4.  The default\n",
       "protocol is 3; a backward-incompatible protocol designed for Python 3.\n",
       "\n",
       "Specifying a negative protocol version selects the highest protocol\n",
       "version supported.  The higher the protocol used, the more recent the\n",
       "version of Python needed to read the pickle produced.\n",
       "\n",
       "The *file* argument must have a write() method that accepts a single\n",
       "bytes argument.  It can thus be a file object opened for binary\n",
       "writing, an io.BytesIO instance, or any other custom object that meets\n",
       "this interface.\n",
       "\n",
       "If *fix_imports* is True and protocol is less than 3, pickle will try\n",
       "to map the new Python 3 names to the old module names used in Python\n",
       "2, so that the pickle data stream is readable with Python 2.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pickle.dump(x, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
